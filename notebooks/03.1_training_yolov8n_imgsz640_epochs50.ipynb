{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZFXj4YyiqHW4kJZZMd26G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"f55f6ad5f53643edade75efc979be03b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_374c9f5ac12b42deb9539e02b269be52","IPY_MODEL_dca738e799a54993b909fdd6e1eae399","IPY_MODEL_15828a5f29b04b6a88ccce80ded81ad7"],"layout":"IPY_MODEL_b705aca078da4ba2a6dc9b5cd0525460"}},"374c9f5ac12b42deb9539e02b269be52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b39fe28cc02048208e0089829a4ee4e2","placeholder":"​","style":"IPY_MODEL_e66dac2f420b4d528e2d6370bb15897d","value":"100%"}},"dca738e799a54993b909fdd6e1eae399":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40b93ec8927248c9b258edec3285691a","max":6534387,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df50b7821d584d5580b54b5d3a3cb5bb","value":6534387}},"15828a5f29b04b6a88ccce80ded81ad7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c02a264cdc34535a7c2a54c213da970","placeholder":"​","style":"IPY_MODEL_6c4aa86a20b34dfbbad50dc050140e76","value":" 6.23M/6.23M [00:00&lt;00:00, 180MB/s]"}},"b705aca078da4ba2a6dc9b5cd0525460":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b39fe28cc02048208e0089829a4ee4e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e66dac2f420b4d528e2d6370bb15897d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40b93ec8927248c9b258edec3285691a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df50b7821d584d5580b54b5d3a3cb5bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c02a264cdc34535a7c2a54c213da970":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c4aa86a20b34dfbbad50dc050140e76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40082781320c46dc82bf3a185d8cc513":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d40f4e8ff645403580ba9e2c12a5cb41","IPY_MODEL_6cbec9483da34fbe93c7d45b93db51b5","IPY_MODEL_5efc33b4c90e4afdb268a8368810a53a"],"layout":"IPY_MODEL_93ab22b724e94cfb919d54ef50a93c1d"}},"d40f4e8ff645403580ba9e2c12a5cb41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89e276226dac4d0b8182d47a7393e0dd","placeholder":"​","style":"IPY_MODEL_f13ab7ae2551455cb3d6963ea2e9a1cd","value":"100%"}},"6cbec9483da34fbe93c7d45b93db51b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f3aee7c1ecd44beb8f0968113ed645c","max":773236,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55d94db156514503a8cca76644ef9edc","value":773236}},"5efc33b4c90e4afdb268a8368810a53a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91030a1aad1047d3a2ee3db1c940cce9","placeholder":"​","style":"IPY_MODEL_40176b9f112649e69f4546d629f5fd1a","value":" 755k/755k [00:00&lt;00:00, 37.2MB/s]"}},"93ab22b724e94cfb919d54ef50a93c1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89e276226dac4d0b8182d47a7393e0dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f13ab7ae2551455cb3d6963ea2e9a1cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f3aee7c1ecd44beb8f0968113ed645c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55d94db156514503a8cca76644ef9edc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91030a1aad1047d3a2ee3db1c940cce9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40176b9f112649e69f4546d629f5fd1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["<a target=\"_blank\" href=\"https://colab.research.google.com/drive/1EMJk0JH3hw7en3CcZY96cRkzKkOnTn03?usp=share_link\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"],"metadata":{"id":"pDSFittEO7k1"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"-1KUvPMGjBQY","executionInfo":{"status":"ok","timestamp":1678980045517,"user_tz":-180,"elapsed":21843,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}}},"outputs":[],"source":["%%capture\n","! pip install pip==21.3.1\n","! pip install ultralytics==8.0.53\n","! pip install clearml==1.9.3"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIAwh-NDloJ8","executionInfo":{"status":"ok","timestamp":1678980090937,"user_tz":-180,"elapsed":45428,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}},"outputId":"430af3e9-95ef-493e-8d26-e59268431881"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from glob import glob\n","import numpy as np\n","import torch\n","import ultralytics\n","from ultralytics import YOLO\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from PIL import Image\n","from clearml import Task"],"metadata":{"id":"S406H9NikDId","executionInfo":{"status":"ok","timestamp":1678980094468,"user_tz":-180,"elapsed":3547,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class cnf:\n","    PROJECT_NAME = \"Pedestrian-Detection-YOLOv8\"\n","    TASK_NAME = \"yolov8n_imgsz640_epochs50\"\n","    CKPT = \"yolov8n.pt\"\n","    IMGSZ = 640\n","    EPOCHS = 50"],"metadata":{"id":"2gGLRRGo_izg","executionInfo":{"status":"ok","timestamp":1678980094469,"user_tz":-180,"elapsed":37,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["ultralytics.checks()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFBAU5v9nyED","executionInfo":{"status":"ok","timestamp":1678980104878,"user_tz":-180,"elapsed":1339,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}},"outputId":"10d0a83e-0e51-42b6-a927-dbde08adafee"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.53 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","Setup complete ✅ (12 CPUs, 83.5 GB RAM, 25.5/166.8 GB disk)\n"]}]},{"cell_type":"code","source":["! clearml-init"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8VbdTUC0Av-","executionInfo":{"status":"ok","timestamp":1678980134183,"user_tz":-180,"elapsed":19995,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}},"outputId":"2ea996fa-2cd2-489d-a55e-cf97b11e70d7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["ClearML SDK setup process\n","\n","Please create new clearml credentials through the settings page in your `clearml-server` web app (e.g. http://localhost:8080//settings/workspace-configuration) \n","Or create a free account at https://app.clear.ml/settings/workspace-configuration\n","\n","In settings page, press \"Create new credentials\", then press \"Copy to clipboard\".\n","\n","Paste copied configuration here:\n","api {      # Reza Zerehpoosh's workspace     web_server: https://app.clear.ml     api_server: https://api.clear.ml     files_server: https://files.clear.ml     credentials {         \"access_key\" = \"J3900LH7LOZ2VAS239KD\"         \"secret_key\"  = \"LjhdVZmdOiH2zQTvVFx7UWpr1xaBFi08QeDkSs1qtUdRfsbo0d\"     } }\n","Detected credentials key=\"J3900LH7LOZ2VAS239KD\" secret=\"Ljhd***\"\n","\n","ClearML Hosts configuration:\n","Web App: https://app.clear.ml\n","API: https://api.clear.ml\n","File Store: https://files.clear.ml\n","\n","Verifying credentials ...\n","Credentials verified!\n","\n","New configuration stored in /root/clearml.conf\n","ClearML setup completed successfully.\n"]}]},{"cell_type":"code","source":["%%shell\n","cp /content/drive/MyDrive/Reza/Projects/Pedestrian-Detection/data/citypersons.zip .\n","unzip -q citypersons.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZguOrMP1kCb_","executionInfo":{"status":"ok","timestamp":1678980168382,"user_tz":-180,"elapsed":28895,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}},"outputId":"bfa0e690-f329-4264-9d51-2179915bdbc5"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# create ClearML experiment and task\n","task = Task.init(project_name=cnf.PROJECT_NAME, task_name=cnf.TASK_NAME)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"224TJcRQ0uyN","executionInfo":{"status":"ok","timestamp":1678980195748,"user_tz":-180,"elapsed":11717,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}},"outputId":"ec1116b4-0cbb-4ef0-8510-ab20121aee32"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["ClearML Task: created new task id=33b4b1fdc9c2464499b02e85c19eed63\n","ClearML results page: https://app.clear.ml/projects/c44ac5edda124f9fa0400f27bf7659c4/experiments/33b4b1fdc9c2464499b02e85c19eed63/output/log\n"]}]},{"cell_type":"code","source":["# load a pretrained model\n","model = YOLO(cnf.CKPT)"],"metadata":{"id":"Msob1jiVmTJc","executionInfo":{"status":"ok","timestamp":1678980244663,"user_tz":-180,"elapsed":11991,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}},"colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["f55f6ad5f53643edade75efc979be03b","374c9f5ac12b42deb9539e02b269be52","dca738e799a54993b909fdd6e1eae399","15828a5f29b04b6a88ccce80ded81ad7","b705aca078da4ba2a6dc9b5cd0525460","b39fe28cc02048208e0089829a4ee4e2","e66dac2f420b4d528e2d6370bb15897d","40b93ec8927248c9b258edec3285691a","df50b7821d584d5580b54b5d3a3cb5bb","7c02a264cdc34535a7c2a54c213da970","6c4aa86a20b34dfbbad50dc050140e76"]},"outputId":"e3e08c68-c39a-4f58-8a20-a92bf3b75510"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/6.23M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f55f6ad5f53643edade75efc979be03b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["2023-03-16 15:23:53,725 - clearml.model - INFO - Selected model id: 96920760883b420098dc25cc39edaf86\n"]}]},{"cell_type":"code","source":["%%time\n","# train the model\n","model.train(data='/content/citypersons/dataset.yaml', imgsz=cnf.IMGSZ, epochs=cnf.EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["40082781320c46dc82bf3a185d8cc513","d40f4e8ff645403580ba9e2c12a5cb41","6cbec9483da34fbe93c7d45b93db51b5","5efc33b4c90e4afdb268a8368810a53a","93ab22b724e94cfb919d54ef50a93c1d","89e276226dac4d0b8182d47a7393e0dd","f13ab7ae2551455cb3d6963ea2e9a1cd","3f3aee7c1ecd44beb8f0968113ed645c","55d94db156514503a8cca76644ef9edc","91030a1aad1047d3a2ee3db1c940cce9","40176b9f112649e69f4546d629f5fd1a"]},"id":"gzN1gmlInV5C","executionInfo":{"status":"ok","timestamp":1678983257286,"user_tz":-180,"elapsed":2998704,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}},"outputId":"2201b212-5c33-47bc-9dfe-daaa3978859b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["New https://pypi.org/project/ultralytics/8.0.54 available 😃 Update with 'pip install -U ultralytics'\n","Ultralytics YOLOv8.0.53 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/citypersons/dataset.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/755k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40082781320c46dc82bf3a185d8cc513"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.Detect                [2, [64, 128, 256]]           \n","Model summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","WARNING ⚠️ ClearML installed but not initialized correctly, not logging this run. Current task already created and requested project name 'YOLOv8' does not match current project name 'Pedestrian-Detection-YOLOv8'. If you wish to create additional tasks use `Task.create`, or close the current task with `task.close()` before calling `Task.init(...)`\n","WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/citypersons/train/labels... 2500 images, 50 backgrounds, 0 corrupt: 100%|██████████| 2550/2550 [00:03<00:00, 743.34it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/citypersons/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/citypersons/valid/labels... 441 images, 10 backgrounds, 0 corrupt: 100%|██████████| 451/451 [00:00<00:00, 482.69it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/citypersons/valid/labels.cache\n","Plotting labels to runs/detect/train/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/50      3.28G      1.841      2.104      1.104        124        640: 100%|██████████| 160/160 [00:44<00:00,  3.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.46it/s]\n","                   all        451       4164      0.367      0.317      0.276      0.138\n"]},{"output_type":"stream","name":"stdout","text":["2023-03-16 15:25:43,568 - clearml.frameworks - INFO - Found existing registered model id=3f6fb710d3634d36ad6e029b3808e613 [/content/runs/detect/train/weights/last.pt] reusing it.\n","2023-03-16 15:25:54,271 - clearml.frameworks - INFO - Found existing registered model id=e962754b91194f3c8c9a912133edcac3 [/content/runs/detect/train/weights/best.pt] reusing it.\n"]},{"output_type":"stream","name":"stderr","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/50      3.29G      1.733      1.483      1.054         95        640: 100%|██████████| 160/160 [00:39<00:00,  4.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.06it/s]\n","                   all        451       4164      0.483      0.334      0.338      0.182\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/50      3.29G      1.771      1.487      1.059         90        640: 100%|██████████| 160/160 [00:40<00:00,  3.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n","                   all        451       4164      0.551      0.315       0.32      0.163\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/50      3.29G       1.74      1.466       1.07         25        640: 100%|██████████| 160/160 [00:40<00:00,  3.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.14it/s]\n","                   all        451       4164      0.512      0.291      0.304      0.164\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/50      3.68G      1.684      1.394      1.053         71        640: 100%|██████████| 160/160 [00:40<00:00,  3.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n","                   all        451       4164      0.562      0.309      0.338      0.189\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/50      3.68G      1.631      1.319       1.04        110        640: 100%|██████████| 160/160 [00:40<00:00,  3.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n","                   all        451       4164      0.574      0.334      0.372      0.211\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/50      3.68G      1.609      1.294      1.031         87        640: 100%|██████████| 160/160 [00:40<00:00,  3.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n","                   all        451       4164      0.616      0.323      0.358      0.201\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/50      3.68G      1.583      1.249      1.025        117        640: 100%|██████████| 160/160 [00:40<00:00,  3.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.06it/s]\n","                   all        451       4164      0.578      0.343      0.376      0.212\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/50      3.68G      1.563      1.235      1.021        107        640: 100%|██████████| 160/160 [00:40<00:00,  3.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.10it/s]\n","                   all        451       4164      0.604      0.332      0.374       0.22\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/50      3.68G      1.545      1.189      1.006        136        640: 100%|██████████| 160/160 [00:40<00:00,  3.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n","                   all        451       4164       0.59      0.343      0.391      0.227\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/50      3.68G      1.513      1.165      1.006         95        640: 100%|██████████| 160/160 [00:40<00:00,  3.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n","                   all        451       4164      0.571      0.359      0.384      0.224\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/50      3.68G      1.513      1.164      1.002        155        640: 100%|██████████| 160/160 [00:40<00:00,  3.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.12it/s]\n","                   all        451       4164      0.569      0.339      0.391      0.228\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/50      3.68G      1.493      1.148     0.9988        163        640: 100%|██████████| 160/160 [00:40<00:00,  3.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n","                   all        451       4164      0.586      0.349      0.396      0.238\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/50      3.68G      1.474      1.133     0.9927        105        640: 100%|██████████| 160/160 [00:40<00:00,  3.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.06it/s]\n","                   all        451       4164      0.625      0.346      0.396      0.234\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/50      3.68G      1.469       1.11     0.9885        124        640: 100%|██████████| 160/160 [00:41<00:00,  3.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.10it/s]\n","                   all        451       4164      0.606      0.359      0.402      0.237\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/50      3.68G      1.443      1.096     0.9766        103        640: 100%|██████████| 160/160 [00:40<00:00,  3.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n","                   all        451       4164      0.664      0.345      0.403      0.245\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/50      3.68G      1.432      1.076     0.9794         66        640: 100%|██████████| 160/160 [00:40<00:00,  3.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n","                   all        451       4164      0.642      0.368      0.424      0.256\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/50      3.68G      1.432      1.078     0.9768         57        640: 100%|██████████| 160/160 [00:40<00:00,  3.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.08it/s]\n","                   all        451       4164      0.594      0.354        0.4      0.241\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/50      3.68G      1.417      1.055     0.9752         80        640: 100%|██████████| 160/160 [00:40<00:00,  3.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.10it/s]\n","                   all        451       4164      0.649      0.375      0.425      0.253\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/50      3.68G      1.419      1.052     0.9679        102        640: 100%|██████████| 160/160 [00:40<00:00,  3.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n","                   all        451       4164      0.626      0.371      0.416      0.251\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/50      3.68G      1.389      1.031      0.974         72        640: 100%|██████████| 160/160 [00:40<00:00,  3.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n","                   all        451       4164      0.633      0.381      0.427      0.258\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/50      3.68G      1.392      1.032     0.9682         74        640: 100%|██████████| 160/160 [00:40<00:00,  3.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n","                   all        451       4164      0.622      0.379      0.426      0.256\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/50      3.68G      1.389      1.017     0.9649         49        640: 100%|██████████| 160/160 [00:39<00:00,  4.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.06it/s]\n","                   all        451       4164      0.618      0.371       0.43      0.263\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/50      3.68G      1.366      1.005     0.9618        110        640: 100%|██████████| 160/160 [00:41<00:00,  3.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.08it/s]\n","                   all        451       4164      0.675      0.374      0.434      0.261\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/50      3.68G      1.357      0.998     0.9576         39        640: 100%|██████████| 160/160 [00:41<00:00,  3.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.06it/s]\n","                   all        451       4164        0.7      0.373      0.434      0.264\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      26/50      3.68G       1.36      0.991     0.9567         58        640: 100%|██████████| 160/160 [00:40<00:00,  3.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n","                   all        451       4164      0.685      0.386      0.442      0.273\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      27/50      3.68G       1.34     0.9828     0.9556        106        640: 100%|██████████| 160/160 [00:40<00:00,  3.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.10it/s]\n","                   all        451       4164       0.66      0.379      0.439      0.266\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      28/50      3.68G      1.327     0.9647     0.9519         73        640: 100%|██████████| 160/160 [00:41<00:00,  3.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n","                   all        451       4164      0.703       0.37       0.44      0.267\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      29/50      3.68G      1.337     0.9721     0.9516        137        640: 100%|██████████| 160/160 [00:39<00:00,  4.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.08it/s]\n","                   all        451       4164      0.619      0.378      0.435      0.266\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      30/50      3.68G      1.329     0.9623      0.952         96        640: 100%|██████████| 160/160 [00:40<00:00,  3.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.08it/s]\n","                   all        451       4164      0.642      0.389      0.449      0.273\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      31/50      3.68G      1.319     0.9634     0.9514         93        640: 100%|██████████| 160/160 [00:40<00:00,  3.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.10it/s]\n","                   all        451       4164      0.641      0.398      0.452      0.279\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      32/50      3.68G      1.307     0.9466     0.9476        103        640: 100%|██████████| 160/160 [00:39<00:00,  4.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.02it/s]\n","                   all        451       4164      0.711      0.376      0.452      0.278\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      33/50      3.68G      1.315       0.95     0.9457         99        640: 100%|██████████| 160/160 [00:39<00:00,  4.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.07it/s]\n","                   all        451       4164      0.692      0.386      0.451      0.279\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      34/50      3.68G      1.304     0.9379     0.9382         95        640: 100%|██████████| 160/160 [00:40<00:00,  3.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n","                   all        451       4164      0.664      0.393      0.458      0.285\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      35/50      3.68G      1.286     0.9262     0.9379         67        640: 100%|██████████| 160/160 [00:40<00:00,  3.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.10it/s]\n","                   all        451       4164      0.714      0.396      0.461      0.284\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      36/50      3.68G      1.288     0.9165     0.9395        124        640: 100%|██████████| 160/160 [00:40<00:00,  3.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n","                   all        451       4164      0.684      0.389      0.452      0.279\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      37/50      3.68G      1.299     0.9266     0.9382         56        640: 100%|██████████| 160/160 [00:41<00:00,  3.84it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.12it/s]\n","                   all        451       4164      0.676      0.401      0.463      0.285\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      38/50      3.68G      1.273     0.9054     0.9351         83        640: 100%|██████████| 160/160 [00:40<00:00,  3.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n","                   all        451       4164      0.697      0.389      0.461      0.286\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      39/50      3.68G      1.262     0.9029     0.9335        121        640: 100%|██████████| 160/160 [00:40<00:00,  3.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n","                   all        451       4164      0.637      0.399      0.457      0.285\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      40/50      3.68G      1.273     0.9044     0.9315         78        640: 100%|██████████| 160/160 [00:40<00:00,  3.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n","                   all        451       4164      0.668      0.393       0.46      0.288\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      41/50      3.68G      1.248     0.8931     0.9299        123        640: 100%|██████████| 160/160 [00:24<00:00,  6.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n","                   all        451       4164      0.637      0.402      0.453      0.283\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      42/50      3.68G      1.225     0.8857     0.9233         31        640: 100%|██████████| 160/160 [00:19<00:00,  8.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.06it/s]\n","                   all        451       4164      0.633       0.39      0.448      0.278\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      43/50      3.68G      1.218     0.8782     0.9228         69        640: 100%|██████████| 160/160 [00:19<00:00,  8.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.01it/s]\n","                   all        451       4164      0.677        0.4      0.459      0.285\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      44/50      3.68G      1.201     0.8632      0.922         17        640: 100%|██████████| 160/160 [00:20<00:00,  7.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.06it/s]\n","                   all        451       4164       0.73      0.386       0.46      0.288\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      45/50      3.68G      1.209     0.8647     0.9177         80        640: 100%|██████████| 160/160 [00:19<00:00,  8.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.03it/s]\n","                   all        451       4164      0.653      0.402      0.456      0.284\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      46/50      3.68G      1.206     0.8578     0.9168         27        640: 100%|██████████| 160/160 [00:20<00:00,  7.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n","                   all        451       4164      0.684      0.402      0.462      0.286\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      47/50      3.68G      1.204     0.8607     0.9207         21        640: 100%|██████████| 160/160 [00:19<00:00,  8.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.06it/s]\n","                   all        451       4164      0.688      0.394      0.461      0.289\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      48/50      3.68G      1.184     0.8353     0.9145         45        640: 100%|██████████| 160/160 [00:20<00:00,  7.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.06it/s]\n","                   all        451       4164      0.698      0.403      0.466      0.291\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      49/50      3.68G      1.184      0.836     0.9106         59        640: 100%|██████████| 160/160 [00:19<00:00,  8.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.06it/s]\n","                   all        451       4164      0.683      0.405      0.465       0.29\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      50/50      3.68G      1.166     0.8241      0.908         19        640: 100%|██████████| 160/160 [00:20<00:00,  8.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.50it/s]\n","                   all        451       4164      0.675      0.401      0.469      0.293\n","\n","50 epochs completed in 0.803 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics YOLOv8.0.53 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","Model summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n","                   all        451       4164      0.675        0.4      0.468      0.293\n","                 rider        451       1007      0.651      0.279      0.336      0.202\n","            pedestrian        451       3157      0.699       0.52        0.6      0.383\n","Speed: 0.3ms preprocess, 0.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["2023-03-16 16:14:09,507 - clearml.Task - INFO - Completed model upload to https://files.clear.ml/Pedestrian-Detection-YOLOv8/yolov8n_imgsz640_epochs50.33b4b1fdc9c2464499b02e85c19eed63/models/best.pt\n","CPU times: user 21min 29s, sys: 3min 29s, total: 24min 59s\n","Wall time: 49min 54s\n"]}]},{"cell_type":"code","source":["# helper functions for ploting predictions\n","def box_label(image, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n","  lw = max(round(sum(image.shape) / 2 * 0.003), 2)\n","  p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n","  cv2.rectangle(image, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)\n","  if label:\n","    tf = max(lw - 1, 1)  # font thickness\n","    w, h = cv2.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[0]  # text width, height\n","    outside = p1[1] - h >= 3\n","    p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n","    cv2.rectangle(image, p1, p2, color, -1, cv2.LINE_AA)  # filled\n","    cv2.putText(image,\n","                label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n","                0,\n","                lw / 3,\n","                txt_color,\n","                thickness=tf,\n","                lineType=cv2.LINE_AA)\n","    \n","def plot_bboxes(image, boxes, labels=[], colors=[], score=True, conf=None):\n","  # Define Labels\n","  if labels == []:\n","    labels = {0: u'__background__', 1: u'rider', 2: u'pedestrian'}\n","  # Define colors\n","  if colors == []:\n","    \n","    colors = [(89, 161, 197), (190, 76, 98), (130, 172, 179), \n","              (67, 161, 255),(19, 222, 24),(186, 55, 2),\n","              (167, 146, 11),(130, 172, 179),(115, 209, 128),\n","              (204, 79, 135),(136, 126, 185),(209, 213, 45),]              \n","  \n","  #plot each boxes\n","  for box in boxes:\n","    #add score in label if score=True\n","    if score :\n","      label = labels[int(box[-1])+1] + \" \" + str(round(100 * float(box[-2]),1)) + \"%\"\n","    else :\n","      label = labels[int(box[-1])+1]\n","    #filter every box under conf threshold if conf threshold setted\n","    if conf :\n","      if box[-2] > conf:\n","        color = colors[int(box[-1])]\n","        box_label(image, box, label, color)\n","    else:\n","      color = colors[int(box[-1])]\n","      box_label(image, box, label, color)\n","\n","  #show image\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","  try:\n","    import google.colab\n","    IN_COLAB = True\n","  except:\n","    IN_COLAB = False\n","\n","  if IN_COLAB:\n","    cv2_imshow(image) #if used in Colab\n","  else :\n","    cv2.imshow(image) #if used in Python"],"metadata":{"id":"7ksZEjRpsClX","executionInfo":{"status":"ok","timestamp":1678983257287,"user_tz":-180,"elapsed":33,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# make prediction on a few validation images and plot the results\n","valid_images = [fp for fp in glob(\"/content/citypersons/valid/images/*.png\")]\n","\n","for fp_img in np.random.choice(valid_images, 5):\n","    preds = model.predict(fp_img);\n","    image = Image.open(fp_img)\n","    image = np.asarray(image)\n","    plot_bboxes(image, preds[0].boxes.boxes, score=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ZOTCz56ErM_ID-JiQPKsBdPmsdTqpON2"},"id":"PxMdGYntqU03","executionInfo":{"status":"ok","timestamp":1678983276976,"user_tz":-180,"elapsed":19721,"user":{"displayName":"Reza Zerehpoosh","userId":"02108206840622331128"}},"outputId":"d6620a95-39de-479b-d4e2-146f76861cd2"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"rh5i__NT-BzI"},"execution_count":null,"outputs":[]}]}