{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/drive/1CAg-Kb7QvhkuIgfyjxNodvFL9jzGR7oJ?usp=sharing\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "aF_8uMEEpyQQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l8fCiKXzplk_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install pip==21.3.1\n",
        "! pip install ultralytics==8.0.53\n",
        "! pip install clearml==1.9.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCs-v-owp4aB",
        "outputId": "9abe04a8-75be-4367-fda6-4deb1b4633ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import clearml\n",
        "from clearml import Task\n",
        "from clearml import Model\n",
        "from ultralytics import YOLO\n",
        "import onnx\n",
        "import onnxruntime as ort"
      ],
      "metadata": {
        "id": "a6Cj_zx8qTsF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clearml.browser_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "ffVJuuqCqTh0",
        "outputId": "fc6c3131-3b66-43c7-b3ba-ac06ccf5e037"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "                    window._ApiKey = new Promise((resolve, reject) => {\n",
              "                        const timeout = setTimeout(() => reject(\"Failed authenticating existing browser session\"), 5000)\n",
              "                        fetch(\"https://app.clear.ml/api/auth.login\", {\n",
              "                          method: 'GET',\n",
              "                          credentials: 'include'\n",
              "                        })\n",
              "                          .then((response) => resolve(response.json()))\n",
              "                          .then((json) => {\n",
              "                            clearTimeout(timeout);\n",
              "                          }).catch((err) => {\n",
              "                            clearTimeout(timeout);\n",
              "                            reject(err);\n",
              "                        });\n",
              "                    });\n",
              "                    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ¤– ClearML connected successfully - let's build something! ðŸš€\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get best performing clearml task\n",
        "task = Task.get_task(\n",
        "    project_name=\"Pedestrian-Detection-YOLOv8\", \n",
        "    task_name=\"yolov8s_imgsz1024_epochs50\",\n",
        ")\n",
        "# download the best model from clearml server\n",
        "best_model_id = task.output_models_id[\"best\"]\n",
        "clearml_model = Model(best_model_id)\n",
        "checkpoint_fp = clearml_model.get_local_copy()\n",
        "print(checkpoint_fp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkfhS_AJt4vB",
        "outputId": "1036e39f-ce50-417a-90a1-111f0170dcac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.clearml/cache/storage_manager/global/83a4f9ffd734970ca8a30c38c37a8b18.best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cp /content/drive/MyDrive/Reza/Projects/Pedestrian-Detection/data/citypersons.zip .\n",
        "unzip -q citypersons.zip"
      ],
      "metadata": {
        "id": "TFzhMs1e2sJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load yolo model from downloaded checkpoint\n",
        "model = YOLO(checkpoint_fp)"
      ],
      "metadata": {
        "id": "UF4JwP6H1D9O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model performance on validation set\n",
        "model.val(\"/content/citypersons/dataset.yaml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBYtPwKgCtLT",
        "outputId": "9e39b052-0cde-48ae-bc53-df85dcadcc7b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.53 ðŸš€ Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/citypersons/valid/labels.cache... 441 images, 10 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 451/451 [00:00<?, ?it/s]\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [08:24<00:00, 17.41s/it]\n",
            "                   all        451       4164      0.721      0.516      0.593      0.405\n",
            "                 rider        451       1007      0.674       0.38      0.441      0.289\n",
            "            pedestrian        451       3157      0.768      0.653      0.744      0.521\n",
            "Speed: 9.1ms preprocess, 1076.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ultralytics.yolo.utils.metrics.DetMetrics at 0x7ff98fdac940>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_fp = \"/content/citypersons/valid/images/frankfurt_000000_009561_leftImg8bit.png\"\n",
        "%timeit result = model.predict(img_fp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvu5_em-AY-9",
        "outputId": "361445ff-fc8c-4092-ba2c-e609aa5a31dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_009561_leftImg8bit.png: 512x1024 1 pedestrian, 692.2ms\n",
            "Speed: 1.6ms preprocess, 692.2ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_009561_leftImg8bit.png: 512x1024 1 pedestrian, 685.1ms\n",
            "Speed: 1.6ms preprocess, 685.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_009561_leftImg8bit.png: 512x1024 1 pedestrian, 669.4ms\n",
            "Speed: 1.6ms preprocess, 669.4ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_009561_leftImg8bit.png: 512x1024 1 pedestrian, 674.1ms\n",
            "Speed: 1.6ms preprocess, 674.1ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_009561_leftImg8bit.png: 512x1024 1 pedestrian, 666.4ms\n",
            "Speed: 1.6ms preprocess, 666.4ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_009561_leftImg8bit.png: 512x1024 1 pedestrian, 696.7ms\n",
            "Speed: 1.5ms preprocess, 696.7ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_009561_leftImg8bit.png: 512x1024 1 pedestrian, 662.5ms\n",
            "Speed: 1.5ms preprocess, 662.5ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_009561_leftImg8bit.png: 512x1024 1 pedestrian, 665.5ms\n",
            "Speed: 1.5ms preprocess, 665.5ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "712 ms Â± 13.6 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the checkpoint to GDrive\n",
        "! cp \"{checkpoint_fp}\" /content/drive/MyDrive/Reza/Projects/Pedestrian-Detection/models/yolov8s_imgsz1024_mAP50_0.593.pt"
      ],
      "metadata": {
        "id": "GoEYMUMaAY8R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tf8I1vmfAYOR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}