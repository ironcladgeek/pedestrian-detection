{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/drive/1CAg-Kb7QvhkuIgfyjxNodvFL9jzGR7oJ?usp=share_link\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "aF_8uMEEpyQQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8fCiKXzplk_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install pip==21.3.1\n",
        "! pip install ultralytics==8.0.53\n",
        "! pip install clearml==1.9.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCs-v-owp4aB",
        "outputId": "bfcd5a66-f338-4c46-ed48-f5ad4249b921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import clearml\n",
        "from clearml import Task\n",
        "from clearml import Model\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "a6Cj_zx8qTsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clearml.browser_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "ffVJuuqCqTh0",
        "outputId": "b39032c5-d7ea-4ee9-ef9f-2b3c24b241d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "                    window._ApiKey = new Promise((resolve, reject) => {\n",
              "                        const timeout = setTimeout(() => reject(\"Failed authenticating existing browser session\"), 5000)\n",
              "                        fetch(\"https://app.clear.ml/api/auth.login\", {\n",
              "                          method: 'GET',\n",
              "                          credentials: 'include'\n",
              "                        })\n",
              "                          .then((response) => resolve(response.json()))\n",
              "                          .then((json) => {\n",
              "                            clearTimeout(timeout);\n",
              "                          }).catch((err) => {\n",
              "                            clearTimeout(timeout);\n",
              "                            reject(err);\n",
              "                        });\n",
              "                    });\n",
              "                    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ¤– ClearML connected successfully - let's build something! ðŸš€\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get best performing clearml task\n",
        "task = Task.get_task(\n",
        "    project_name=\"Pedestrian-Detection-YOLOv8\", \n",
        "    task_name=\"yolov8s_imgsz1024_epochs50\",\n",
        ")\n",
        "# download the best model from clearml server\n",
        "best_model_id = task.output_models_id[\"best\"]\n",
        "clearml_model = Model(best_model_id)\n",
        "checkpoint_fp = clearml_model.get_local_copy()\n",
        "print(checkpoint_fp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkfhS_AJt4vB",
        "outputId": "0e3498f2-86b1-4ffb-a5e7-8ce57f82115f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-18 20:05:28,094 - clearml.storage - INFO - Downloading: 5.00MB / 21.47MB @ 16.63MBs from https://files.clear.ml/Pedestrian-Detection-YOLOv8/yolov8s_imgsz1024_epochs50.5b25d74ef1cc4f5686b1a424b6296095/models/best.pt\n",
            "2023-03-18 20:05:28,155 - clearml.storage - INFO - Downloading: 10.00MB / 21.47MB @ 81.98MBs from https://files.clear.ml/Pedestrian-Detection-YOLOv8/yolov8s_imgsz1024_epochs50.5b25d74ef1cc4f5686b1a424b6296095/models/best.pt\n",
            "2023-03-18 20:05:28,259 - clearml.storage - INFO - Downloading: 15.00MB / 21.47MB @ 48.16MBs from https://files.clear.ml/Pedestrian-Detection-YOLOv8/yolov8s_imgsz1024_epochs50.5b25d74ef1cc4f5686b1a424b6296095/models/best.pt\n",
            "2023-03-18 20:05:28,315 - clearml.storage - INFO - Downloading: 20.00MB / 21.47MB @ 89.68MBs from https://files.clear.ml/Pedestrian-Detection-YOLOv8/yolov8s_imgsz1024_epochs50.5b25d74ef1cc4f5686b1a424b6296095/models/best.pt\n",
            "2023-03-18 20:05:28,331 - clearml.storage - INFO - Downloaded 21.47 MB successfully from https://files.clear.ml/Pedestrian-Detection-YOLOv8/yolov8s_imgsz1024_epochs50.5b25d74ef1cc4f5686b1a424b6296095/models/best.pt , saved to /root/.clearml/cache/storage_manager/global/83a4f9ffd734970ca8a30c38c37a8b18.best.pt\n",
            "/root/.clearml/cache/storage_manager/global/83a4f9ffd734970ca8a30c38c37a8b18.best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cp /content/drive/MyDrive/Reza/Projects/Pedestrian-Detection/data/citypersons.zip .\n",
        "unzip -q citypersons.zip"
      ],
      "metadata": {
        "id": "TFzhMs1e2sJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff64667-34ed-4ca2-e2c0-a8d6852a6b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load yolo model from downloaded checkpoint\n",
        "model = YOLO(checkpoint_fp)"
      ],
      "metadata": {
        "id": "UF4JwP6H1D9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_fp = \"/content/citypersons/valid/images/frankfurt_000000_002196_leftImg8bit.png\"\n",
        "%timeit result = model.predict(img_fp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvu5_em-AY-9",
        "outputId": "814316be-d79d-4512-89fb-6b14e2618d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_002196_leftImg8bit.png: 512x1024 5 pedestrians, 748.7ms\n",
            "Speed: 1.8ms preprocess, 748.7ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_002196_leftImg8bit.png: 512x1024 5 pedestrians, 757.9ms\n",
            "Speed: 1.5ms preprocess, 757.9ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_002196_leftImg8bit.png: 512x1024 5 pedestrians, 715.3ms\n",
            "Speed: 1.5ms preprocess, 715.3ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_002196_leftImg8bit.png: 512x1024 5 pedestrians, 700.3ms\n",
            "Speed: 1.5ms preprocess, 700.3ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_002196_leftImg8bit.png: 512x1024 5 pedestrians, 752.0ms\n",
            "Speed: 1.7ms preprocess, 752.0ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_002196_leftImg8bit.png: 512x1024 5 pedestrians, 1026.4ms\n",
            "Speed: 1.5ms preprocess, 1026.4ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_002196_leftImg8bit.png: 512x1024 5 pedestrians, 1165.3ms\n",
            "Speed: 3.3ms preprocess, 1165.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000000_002196_leftImg8bit.png: 512x1024 5 pedestrians, 1222.1ms\n",
            "Speed: 1.6ms preprocess, 1222.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "946 ms Â± 218 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_fp = \"/content/citypersons/valid/images/frankfurt_000001_016029_leftImg8bit.png\"\n",
        "result = model.predict(img_fp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifiqc-w4aAeR",
        "outputId": "2ff256ae-5b39-4995-bc56-9dd29688cc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/citypersons/valid/images/frankfurt_000001_016029_leftImg8bit.png: 512x1024 3 riders, 11 pedestrians, 953.2ms\n",
            "Speed: 7.2ms preprocess, 953.2ms inference, 33.6ms postprocess per image at shape (1, 3, 1024, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model performance on validation set\n",
        "model.val(\"/content/citypersons/dataset.yaml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBYtPwKgCtLT",
        "outputId": "9e39b052-0cde-48ae-bc53-df85dcadcc7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.53 ðŸš€ Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/citypersons/valid/labels.cache... 441 images, 10 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 451/451 [00:00<?, ?it/s]\n",
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [08:24<00:00, 17.41s/it]\n",
            "                   all        451       4164      0.721      0.516      0.593      0.405\n",
            "                 rider        451       1007      0.674       0.38      0.441      0.289\n",
            "            pedestrian        451       3157      0.768      0.653      0.744      0.521\n",
            "Speed: 9.1ms preprocess, 1076.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ultralytics.yolo.utils.metrics.DetMetrics at 0x7ff98fdac940>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the checkpoint to GDrive\n",
        "! cp \"{checkpoint_fp}\" /content/drive/MyDrive/Reza/Projects/Pedestrian-Detection/models/yolov8s_imgsz1024_mAP50_0.593.pt"
      ],
      "metadata": {
        "id": "GoEYMUMaAY8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tf8I1vmfAYOR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}